{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f4a7e9-e33a-4d85-82a2-e54889f12d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- followers_count: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- favourites_count: integer (nullable = true)\n",
      " |-- reblogs_count: integer (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n",
      "Tokenizer pour diviser le content du tweet en mots\n",
      "Convertir les mots en vecteurs de caractéristiques en utilisant CountVectorizer\n",
      "Accuracy: 0.00\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m historical_data \u001b[38;5;241m=\u001b[39m df \u001b[38;5;66;03m# Assurez-vous que la table est chargée dans Spark\u001b[39;00m\n\u001b[1;32m     76\u001b[0m tokenized_historical_data \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtransform(historical_data)\n\u001b[0;32m---> 77\u001b[0m vectorized_historical_data \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m(tokenized_historical_data)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Prédire les sentiments\u001b[39;00m\n\u001b[1;32m     80\u001b[0m sentiment_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(vectorized_historical_data)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import psycopg2\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Initialiser SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AnalyseDeSentiment\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.2.25\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Paramètres de connexion PostgreSQL\n",
    "db_url = \"jdbc:postgresql://projetfinal5spar-postgres-1:5432/mastodon_data\"\n",
    "db_properties = {\n",
    "    \"user\": \"user\",\n",
    "    \"password\": \"password\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Charger les données historiques de PostgreSQL\n",
    "df = spark.read \\\n",
    "    .jdbc(url=db_url, table=\"mastodon\", properties=db_properties)\n",
    "\n",
    "# Afficher le schéma des données\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"label\",\n",
    "    when(\n",
    "        (col(\"content\").contains(\"fou\")) |\n",
    "        (col(\"content\").contains(\"dangereux\")) |\n",
    "        (col(\"content\").contains(\"enfermer\")),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "\n",
    "print(f\"Tokenizer pour diviser le content du tweet en mots\")\n",
    "tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"words\")\n",
    "tokenized_df = tokenizer.transform(df)\n",
    "\n",
    "print(f\"Convertir les mots en vecteurs de caractéristiques en utilisant CountVectorizer\")\n",
    "vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
    "vectorized_df = vectorizer.fit(tokenized_df).transform(tokenized_df)\n",
    "\n",
    "\n",
    "# Configuration de la régression logistique\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Création d'un pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, vectorizer, lr])\n",
    "\n",
    "# Diviser les données en ensembles d’entraînement et de test\n",
    "(train_data, test_data) = df.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Prédire sur les données de test\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Évaluer la précision du modèle\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Appliquer le modèle formé sur les données historiques Mastodon\n",
    "historical_data = df # Assurez-vous que la table est chargée dans Spark\n",
    "tokenized_historical_data = tokenizer.transform(historical_data)\n",
    "vectorized_historical_data = vectorizer.transform(tokenized_historical_data)\n",
    "\n",
    "# Prédire les sentiments\n",
    "sentiment_predictions = model.transform(vectorized_historical_data)\n",
    "\n",
    "\n",
    "# Paramètres de connexion à PostgreSQL\n",
    "db_host = \"projetfinal5spar-postgres-1\"\n",
    "db_port = \"5432\"\n",
    "db_name = \"mastodon_data\"\n",
    "db_user = \"user\"\n",
    "db_password = \"password\"\n",
    "db_url = f\"jdbc:postgresql://{db_host}:{db_port}/{db_name}\"\n",
    "db_properties = {\n",
    "    \"user\": db_user,\n",
    "    \"password\": db_password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Fonction pour initialiser la table mastodon dans PostgreSQL\n",
    "def initialize_sentiment_results_table():\n",
    "    print(\"Initialisation de la table mastodon dans PostgreSQL...\")\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=db_properties[\"user\"],\n",
    "            password=db_properties[\"password\"],\n",
    "            host=db_host,\n",
    "            port=db_port\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        create_table_sql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS sentiment_results (\n",
    "            \"id\" VARCHAR(255),\n",
    "            content TEXT,\n",
    "            sentiment VARCHAR(255),\n",
    "            PRIMARY KEY (\"id\")\n",
    "        );\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(create_table_sql)\n",
    "        print(\"Table sentiment_results initialisée avec succès dans PostgreSQL.\")\n",
    "\n",
    "        # Ajout d'une contrainte d'unicité si nécessaire\n",
    "        cursor.execute(\"\"\"\n",
    "        ALTER TABLE sentiment_results ADD CONSTRAINT unique_sentiment UNIQUE (\"id\");\n",
    "        \"\"\")\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur lors de l'initialisation de la table sentiment_results dans PostgreSQL: {e}\")\n",
    "        print(f\"Erreur lors de l'initialisation de la table sentiment_results: {e}\")\n",
    "\n",
    "\n",
    "# Initialiser la table mastodon\n",
    "initialize_sentiment_results_table()\n",
    "\n",
    "\n",
    "# Fonction pour stocker les résultats dans PostgreSQL\n",
    "def store_sentiment_results(dataframe):\n",
    "    print(\"Stockage des résultats dans PostgreSQL...\")\n",
    "    try:\n",
    "        # Convertir le DataFrame Spark en DataFrame Pandas\n",
    "        pandas_df = dataframe.select(\"id\", \"content\", \"prediction\").toPandas()\n",
    "\n",
    "        # Connexion à PostgreSQL\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_password,\n",
    "            host=db_host,\n",
    "            port=db_port\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Insertion des résultats\n",
    "        for _, row in pandas_df.iterrows():\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO sentiment_results (id, content, sentiment)\n",
    "                VALUES (%s, %s, %s)\n",
    "                ON CONFLICT (id) DO UPDATE SET\n",
    "                content = EXCLUDED.content,\n",
    "                sentiment = EXCLUDED.sentiment\n",
    "            \"\"\", (\n",
    "                row['id'],\n",
    "                row['content'],\n",
    "                row['prediction']\n",
    "            ))\n",
    "\n",
    "        print(\"Résultats stockés avec succès dans 'sentiment_results'.\")\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur lors de l'insertion dans 'sentiment_results' : {e}\")\n",
    "        print(f\"Erreur lors de l'insertion dans 'sentiment_results' : {e}\")\n",
    "\n",
    "# Appeler la fonction pour stocker les résultats\n",
    "store_sentiment_results(sentiment_predictions)\n",
    "\n",
    "\n",
    "print(\"Traitement terminé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc97602-844c-496b-8c0e-980c21c1eaff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
