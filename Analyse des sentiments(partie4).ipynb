{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "920d924f-7e5b-419c-87fe-3ebde1b3e9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- followers_count: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- favourites_count: integer (nullable = true)\n",
      " |-- reblogs_count: integer (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n",
      "Tokenizer pour diviser le content du tweet en mots\n",
      "Convertir les mots en vecteurs de caractéristiques en utilisant CountVectorizer\n",
      "Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Erreur lors de l'initialisation de la table sentiment_results dans PostgreSQL: relation \"unique_sentiment\" already exists\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation de la table mastodon dans PostgreSQL...\n",
      "Table sentiment_results initialisée avec succès dans PostgreSQL.\n",
      "Erreur lors de l'initialisation de la table sentiment_results: relation \"unique_sentiment\" already exists\n",
      "\n",
      "Stockage des résultats dans PostgreSQL...\n",
      "Résultats stockés avec succès dans 'sentiment_results'.\n",
      "Traitement terminé.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import psycopg2\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import when, col, udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# Initialiser SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AnalyseDeSentiment\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.2.25\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Paramètres de connexion PostgreSQL\n",
    "db_url = \"jdbc:postgresql://projetfinal5spar-postgres-1:5432/mastodon_data\"\n",
    "db_properties = {\n",
    "    \"user\": \"user\",\n",
    "    \"password\": \"password\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Charger les données historiques de PostgreSQL\n",
    "df = spark.read \\\n",
    "    .jdbc(url=db_url, table=\"mastodon\", properties=db_properties)\n",
    "\n",
    "\n",
    "# Initialiser l'analyseur VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Fonction pour obtenir le score de sentiment\n",
    "def get_score(text):\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "# UDF pour appliquer la fonction de sentiment\n",
    "sentiment = udf(get_score, FloatType())\n",
    "\n",
    "# Appliquer l'UDF pour obtenir les scores de sentiment\n",
    "df = df.withColumn(\"score\", sentiment(col(\"content\")))\n",
    "\n",
    "# Création du champs label et ajout des valeurs\n",
    "df = df.withColumn(\"label\", when(col(\"score\") >= 0, 1).otherwise(0))\n",
    "\n",
    "\n",
    "\n",
    "# Afficher le schéma des données\n",
    "df.printSchema()\n",
    "\n",
    "\n",
    "print(f\"Tokenizer pour diviser le content du tweet en mots\")\n",
    "tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"words\")\n",
    "tokenized_df = tokenizer.transform(df)\n",
    "\n",
    "print(f\"Convertir les mots en vecteurs de caractéristiques en utilisant CountVectorizer\")\n",
    "vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
    "vectorized_df = vectorizer.fit(tokenized_df).transform(tokenized_df)\n",
    "\n",
    "\n",
    "# Configuration de la régression logistique\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Création d'un pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, vectorizer, lr])\n",
    "\n",
    "# Diviser les données en ensembles d’entraînement et de test\n",
    "(train_data, test_data) = df.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Prédire sur les données de test\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Évaluer la précision du modèle\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Prédire les sentiments\n",
    "sentiment_predictions = model.transform(df)\n",
    "\n",
    "\n",
    "# Paramètres de connexion à PostgreSQL\n",
    "db_host = \"projetfinal5spar-postgres-1\"\n",
    "db_port = \"5432\"\n",
    "db_name = \"mastodon_data\"\n",
    "db_user = \"user\"\n",
    "db_password = \"password\"\n",
    "db_url = f\"jdbc:postgresql://{db_host}:{db_port}/{db_name}\"\n",
    "db_properties = {\n",
    "    \"user\": db_user,\n",
    "    \"password\": db_password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Fonction pour initialiser la table sentiment_results dans PostgreSQL\n",
    "def initialize_sentiment_results_table():\n",
    "    print(\"Initialisation de la table sentiment_results dans PostgreSQL...\")\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=db_properties[\"user\"],\n",
    "            password=db_properties[\"password\"],\n",
    "            host=db_host,\n",
    "            port=db_port\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        create_table_sql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS sentiment_results (\n",
    "            \"id\" VARCHAR(255),\n",
    "            content TEXT,\n",
    "            sentiment VARCHAR(255),\n",
    "            PRIMARY KEY (\"id\")\n",
    "        );\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(create_table_sql)\n",
    "        print(\"Table sentiment_results initialisée avec succès dans PostgreSQL.\")\n",
    "\n",
    "        # Ajout d'une contrainte d'unicité si nécessaire\n",
    "        cursor.execute(\"\"\"\n",
    "        ALTER TABLE sentiment_results ADD CONSTRAINT unique_sentiment UNIQUE (\"id\");\n",
    "        \"\"\")\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur lors de l'initialisation de la table sentiment_results dans PostgreSQL: {e}\")\n",
    "        print(f\"Erreur lors de l'initialisation de la table sentiment_results: {e}\")\n",
    "\n",
    "\n",
    "# Initialiser la table sentiment_results\n",
    "initialize_sentiment_results_table()\n",
    "\n",
    "\n",
    "# Fonction pour stocker les résultats dans PostgreSQL\n",
    "def store_sentiment_results(dataframe):\n",
    "    print(\"Stockage des résultats dans PostgreSQL...\")\n",
    "    try:\n",
    "        # Convertir le DataFrame Spark en DataFrame Pandas\n",
    "        pandas_df = dataframe.select(\"id\", \"content\", \"prediction\").toPandas()\n",
    "\n",
    "        # Connexion à PostgreSQL\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_password,\n",
    "            host=db_host,\n",
    "            port=db_port\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Insertion des résultats\n",
    "        for _, row in pandas_df.iterrows():\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO sentiment_results (id, content, sentiment)\n",
    "                VALUES (%s, %s, %s)\n",
    "                ON CONFLICT (id) DO UPDATE SET\n",
    "                content = EXCLUDED.content,\n",
    "                sentiment = EXCLUDED.sentiment\n",
    "            \"\"\", (\n",
    "                row['id'],\n",
    "                row['content'],\n",
    "                row['prediction']\n",
    "            ))\n",
    "\n",
    "        print(\"Résultats stockés avec succès dans 'sentiment_results'.\")\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur lors de l'insertion dans 'sentiment_results' : {e}\")\n",
    "        print(f\"Erreur lors de l'insertion dans 'sentiment_results' : {e}\")\n",
    "\n",
    "# Appeler la fonction pour stocker les résultats\n",
    "store_sentiment_results(sentiment_predictions)\n",
    "\n",
    "\n",
    "print(\"Traitement terminé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1692922-aae7-467b-a314-5306113e12d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
